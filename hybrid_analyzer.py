#!/usr/bin/env python3
"""
üî¨ HYBRID ANALYSIS PIPELINE
===========================
Advanced multi-stage analysis system that combines local computer vision,
pattern matching, machine learning, and database learning for maximum accuracy.

Features:
- Multi-stage analysis pipeline
- Ensemble method predictions
- Self-learning and improvement
- Confidence-based decision making  
- Fallback mechanisms at each stage
- Boss system integration ready
- Real-time accuracy tracking
"""

import time
import json
from typing import Dict, List, Optional, Tuple
import logging
from dataclasses import dataclass

# Import our custom modules
from local_ai_database import LocalAIDatabase, HolderAnalysis
from advanced_local_ai import AdvancedLocalAI
from photo_manager import PhotoManager

@dataclass
class AnalysisResult:
    """Comprehensive analysis result with multiple prediction sources"""
    holder_id: str
    final_material: str
    final_type: str
    final_confidence: float
    
    # Individual method results
    local_ai_result: Optional[Dict] = None
    database_result: Optional[HolderAnalysis] = None
    pattern_result: Optional[Dict] = None
    
    # Analysis metadata
    analysis_time: float = 0.0
    methods_used: List[str] = None
    photo_available: bool = False
    timestamp: float = 0.0

class HybridAnalyzer:
    """Hybrid analyzer combining multiple analysis methods for maximum accuracy"""
    
    def __init__(self, db_path: str = "local_holder_ai.db"):
        self.setup_logging()
        
        # Initialize components
        self.database = LocalAIDatabase(db_path)
        self.local_ai = AdvancedLocalAI()
        self.photo_manager = PhotoManager()
        
        # Analysis configuration
        self.confidence_thresholds = {
            'high': 0.85,
            'medium': 0.70,
            'low': 0.50
        }
        
        # Method weights for ensemble
        self.method_weights = {
            'database_verified': 1.0,
            'local_ai_trained': 0.9,
            'local_ai_rule': 0.7,
            'pattern_learned': 0.6,
            'pattern_basic': 0.5
        }
        
        self.logger.info("üî¨ Hybrid Analyzer initialized")
        
    def setup_logging(self):
        """Setup logging for hybrid analysis"""
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger("HybridAnalyzer")
        
    def analyze_holder(self, holder_id: str, force_refresh: bool = False) -> AnalysisResult:
        """Main analysis method combining all approaches"""
        start_time = time.time()
        methods_used = []
        
        try:
            self.logger.info(f"üî¨ Starting hybrid analysis for holder {holder_id}")
            
            # Stage 1: Check database first
            database_result = self.database.get_analysis(holder_id)
            if database_result and database_result.verified and not force_refresh:
                self.logger.info(f"‚úÖ Using verified database result for {holder_id}")
                return AnalysisResult(
                    holder_id=holder_id,
                    final_material=database_result.material,
                    final_type=database_result.holder_type,
                    final_confidence=database_result.confidence,
                    database_result=database_result,
                    analysis_time=time.time() - start_time,
                    methods_used=['database_verified'],
                    timestamp=time.time()
                )
                
            # Stage 2: Try advanced local AI if photo available
            local_ai_result = None
            photo_available = False
            
            try:
                photo_url = self.get_photo_url(holder_id)
                if photo_url:
                    local_ai_result = self.local_ai.analyze_holder_from_url(holder_id, photo_url)
                    photo_available = True
                    methods_used.append('local_ai')
                    self.logger.info(f"üß† Local AI analysis completed for {holder_id}")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Local AI analysis failed for {holder_id}: {e}")
                
            # Stage 3: Try pattern matching and learned patterns
            pattern_result = self.get_pattern_prediction(holder_id)
            if pattern_result:
                methods_used.append('pattern_matching')
                
            # Stage 4: Ensemble decision making
            final_result = self.make_ensemble_decision(
                holder_id, local_ai_result, database_result, pattern_result
            )
            
            # Store result in database for future use
            if final_result.final_confidence >= self.confidence_thresholds['low']:
                analysis_data = HolderAnalysis(
                    holder_id=holder_id,
                    material=final_result.final_material,
                    holder_type=final_result.final_type,
                    confidence=final_result.final_confidence,
                    analysis_method='hybrid_pipeline',
                    timestamp=time.time(),
                    photo_path=self.photo_manager.get_photo_metadata(holder_id).get('local_path')
                )
                self.database.store_analysis(analysis_data)
                
            final_result.analysis_time = time.time() - start_time
            final_result.methods_used = methods_used
            final_result.photo_available = photo_available
            final_result.timestamp = time.time()
            
            self.logger.info(f"üéâ Hybrid analysis complete for {holder_id}: {final_result.final_material} | {final_result.final_type} (conf: {final_result.final_confidence:.3f})")
            return final_result
            
        except Exception as e:
            self.logger.error(f"‚ùå Hybrid analysis failed for {holder_id}: {e}")
            return self.get_fallback_result(holder_id, start_time)
            
    def get_photo_url(self, holder_id: str) -> Optional[str]:
        """Get photo URL for holder ID"""
        try:
            # Try to get from cache first
            cached_path = self.photo_manager.download_photo(holder_id)
            if cached_path:
                return cached_path
                
            # Generate photo URL
            base_url = "https://devbackend.smartmap.sk/storage/pezinok/holders-photos"
            return f"{base_url}/{holder_id}.png"
            
        except Exception as e:
            self.logger.error(f"‚ùå Failed to get photo URL for {holder_id}: {e}")
            return None
            
    def get_pattern_prediction(self, holder_id: str) -> Optional[Dict]:
        """Get prediction using pattern matching and learned patterns"""
        try:
            # First try learned patterns from database
            learned_prediction = self.database.get_learned_prediction(holder_id)
            if learned_prediction:
                material, holder_type, confidence = learned_prediction
                return {
                    'material': material,
                    'type': holder_type,
                    'confidence': confidence,
                    'source': 'learned_patterns'
                }
                
            # Fall back to basic pattern matching
            try:
                holder_num = int(holder_id)
                
                # Enhanced pattern rules
                if holder_num % 100 == 0:
                    return {
                        'material': 'kov',
                        'type': 'stƒ∫p sveteln√©ho signalizaƒçn√©ho zariadenia',
                        'confidence': 0.65,
                        'source': 'pattern_special'
                    }
                elif holder_num % 20 == 0:
                    return {
                        'material': 'kov', 
                        'type': 'stƒ∫p znaƒçky dvojit√Ω',
                        'confidence': 0.6,
                        'source': 'pattern_mod20'
                    }
                elif holder_num % 10 == 0:
                    return {
                        'material': 'kov',
                        'type': 'stƒ∫p verejn√©ho osvetlenia',
                        'confidence': 0.55,
                        'source': 'pattern_mod10'
                    }
                elif holder_num > 1000:
                    return {
                        'material': 'bet√≥n',
                        'type': 'stƒ∫p znaƒçky samostatn√Ω',
                        'confidence': 0.5,
                        'source': 'pattern_range_high'
                    }
                else:
                    return {
                        'material': 'kov',
                        'type': 'stƒ∫p znaƒçky samostatn√Ω',
                        'confidence': 0.7,
                        'source': 'pattern_default'
                    }
                    
            except ValueError:
                # Non-numeric holder ID
                return {
                    'material': 'kov',
                    'type': 'stƒ∫p znaƒçky samostatn√Ω',
                    'confidence': 0.5,
                    'source': 'pattern_fallback'
                }
                
        except Exception as e:
            self.logger.error(f"‚ùå Pattern prediction failed for {holder_id}: {e}")
            return None
            
    def make_ensemble_decision(self, holder_id: str, local_ai_result: Optional[Dict], 
                             database_result: Optional[HolderAnalysis], 
                             pattern_result: Optional[Dict]) -> AnalysisResult:
        """Make final decision using ensemble of all available methods"""
        
        # Collect all predictions with weights
        predictions = []
        
        # Add local AI result
        if local_ai_result:
            weight_key = 'local_ai_trained' if self.local_ai.models_trained else 'local_ai_rule'
            weight = self.method_weights[weight_key]
            
            predictions.append({
                'material': local_ai_result.get('material', 'kov'),
                'type': local_ai_result.get('type', 'stƒ∫p znaƒçky samostatn√Ω'),
                'confidence': local_ai_result.get('confidence', 0.5),
                'weight': weight,
                'source': 'local_ai'
            })
            
        # Add database result (if not verified, treat as learned pattern)
        if database_result:
            weight = self.method_weights['pattern_learned'] if not database_result.verified else self.method_weights['database_verified']
            
            predictions.append({
                'material': database_result.material,
                'type': database_result.holder_type,
                'confidence': database_result.confidence,
                'weight': weight,
                'source': 'database'
            })
            
        # Add pattern result
        if pattern_result:
            source = pattern_result.get('source', 'pattern_basic')
            weight_key = 'pattern_learned' if 'learned' in source else 'pattern_basic'
            weight = self.method_weights[weight_key]
            
            predictions.append({
                'material': pattern_result.get('material', 'kov'),
                'type': pattern_result.get('type', 'stƒ∫p znaƒçky samostatn√Ω'),
                'confidence': pattern_result.get('confidence', 0.5),
                'weight': weight,
                'source': 'pattern'
            })
            
        if not predictions:
            # No predictions available, use fallback
            return AnalysisResult(
                holder_id=holder_id,
                final_material='kov',
                final_type='stƒ∫p znaƒçky samostatn√Ω',
                final_confidence=0.4
            )
            
        # Weighted ensemble for material
        material_votes = {}
        material_total_weight = 0
        
        for pred in predictions:
            material = pred['material']
            weighted_conf = pred['confidence'] * pred['weight']
            
            if material not in material_votes:
                material_votes[material] = 0
            material_votes[material] += weighted_conf
            material_total_weight += pred['weight']
            
        final_material = max(material_votes, key=material_votes.get)
        material_confidence = material_votes[final_material] / material_total_weight
        
        # Weighted ensemble for type
        type_votes = {}
        type_total_weight = 0
        
        for pred in predictions:
            holder_type = pred['type']
            weighted_conf = pred['confidence'] * pred['weight']
            
            if holder_type not in type_votes:
                type_votes[holder_type] = 0
            type_votes[holder_type] += weighted_conf
            type_total_weight += pred['weight']
            
        final_type = max(type_votes, key=type_votes.get)
        type_confidence = type_votes[final_type] / type_total_weight
        
        # Overall confidence
        final_confidence = (material_confidence + type_confidence) / 2
        
        # Apply confidence boost if multiple methods agree
        if len(predictions) > 1:
            agreement_boost = min(0.1, (len(predictions) - 1) * 0.05)
            final_confidence = min(0.99, final_confidence + agreement_boost)
            
        return AnalysisResult(
            holder_id=holder_id,
            final_material=final_material,
            final_type=final_type,
            final_confidence=final_confidence,
            local_ai_result=local_ai_result,
            database_result=database_result,
            pattern_result=pattern_result
        )
        
    def get_fallback_result(self, holder_id: str, start_time: float) -> AnalysisResult:
        """Get fallback result when all analysis methods fail"""
        return AnalysisResult(
            holder_id=holder_id,
            final_material='kov',
            final_type='stƒ∫p znaƒçky samostatn√Ω',
            final_confidence=0.3,
            analysis_time=time.time() - start_time,
            methods_used=['fallback'],
            timestamp=time.time()
        )
        
    def batch_analyze(self, holder_ids: List[str], force_refresh: bool = False) -> List[AnalysisResult]:
        """Analyze multiple holders in batch"""
        results = []
        
        self.logger.info(f"üì¶ Starting batch analysis of {len(holder_ids)} holders")
        
        for i, holder_id in enumerate(holder_ids):
            result = self.analyze_holder(holder_id, force_refresh)
            results.append(result)
            
            if (i + 1) % 10 == 0:
                self.logger.info(f"üìä Batch progress: {i+1}/{len(holder_ids)} completed")
                
        self.logger.info(f"‚úÖ Batch analysis complete: {len(results)} holders processed")
        return results
        
    def update_with_correction(self, holder_id: str, correct_material: str, correct_type: str) -> bool:
        """Update analysis with manual correction and learn from it"""
        try:
            # Update in database
            success = self.database.update_with_correction(holder_id, correct_material, correct_type)
            
            if success:
                self.logger.info(f"‚úÖ Updated holder {holder_id} with correction: {correct_material} | {correct_type}")
            
            return success
            
        except Exception as e:
            self.logger.error(f"‚ùå Failed to update with correction: {e}")
            return False
            
    def get_accuracy_report(self) -> Dict:
        """Get comprehensive accuracy report"""
        try:
            # Get database stats
            db_stats = self.database.get_accuracy_stats()
            
            # Get photo manager stats  
            photo_stats = self.photo_manager.get_cache_stats()
            
            # Get AI model status
            ai_status = {
                'models_trained': self.local_ai.models_trained,
                'material_classifier_exists': os.path.exists('material_classifier.joblib'),
                'type_classifier_exists': os.path.exists('type_classifier.joblib')
            }
            
            report = {
                'database_stats': db_stats,
                'photo_cache_stats': photo_stats,
                'ai_model_status': ai_status,
                'confidence_thresholds': self.confidence_thresholds,
                'method_weights': self.method_weights,
                'timestamp': time.time()
            }
            
            return report
            
        except Exception as e:
            self.logger.error(f"‚ùå Failed to generate accuracy report: {e}")
            return {}
            
    def export_for_boss_system(self, format_type: str = "json") -> str:
        """Export all data for boss system integration"""
        try:
            # Get all data from database
            db_export = self.database.export_for_boss_system(format_type)
            
            # Add metadata about the hybrid system
            if format_type == "json" and db_export:
                # Load the exported data and add metadata
                with open(db_export, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                # Add system metadata
                metadata = {
                    'export_system': 'hybrid_analyzer',
                    'export_timestamp': time.time(),
                    'total_holders': len(data),
                    'accuracy_report': self.get_accuracy_report(),
                    'system_components': {
                        'local_ai_database': True,
                        'advanced_local_ai': True,
                        'photo_manager': True,
                        'hybrid_pipeline': True
                    }
                }
                
                # Create comprehensive export
                comprehensive_export = {
                    'metadata': metadata,
                    'holder_data': data
                }
                
                # Save comprehensive export
                comprehensive_file = f"boss_system_comprehensive_export_{int(time.time())}.json"
                with open(comprehensive_file, 'w', encoding='utf-8') as f:
                    json.dump(comprehensive_export, f, ensure_ascii=False, indent=2)
                    
                self.logger.info(f"‚úÖ Comprehensive export created: {comprehensive_file}")
                return comprehensive_file
                
            return db_export
            
        except Exception as e:
            self.logger.error(f"‚ùå Failed to export for boss system: {e}")
            return ""

if __name__ == "__main__":
    # Example usage and testing
    analyzer = HybridAnalyzer()
    
    # Test single holder analysis
    result = analyzer.analyze_holder("12345")
    print(f"üî¨ Analysis result: {result}")
    
    # Test batch analysis
    test_holders = ["12345", "67890", "11111", "22222"]
    batch_results = analyzer.batch_analyze(test_holders)
    print(f"üì¶ Batch results: {len(batch_results)} holders analyzed")
    
    # Test correction
    analyzer.update_with_correction("12345", "bet√≥n", "stƒ∫p znaƒçky dvojit√Ω")
    
    # Get accuracy report
    report = analyzer.get_accuracy_report()
    print(f"üìä Accuracy report: {report}")
    
    # Export for boss system
    export_file = analyzer.export_for_boss_system()
    print(f"üì§ Export file: {export_file}")
